# Storage

The ADC Cluster provides an array of data storage platforms, each designed with a particular purpose in mind. Storage areas are broadly divided into two categories: those intended for user data and those intended for project data. Within each of the two categories, we provide different sub-areas, each with an intended purpose:

| Purpose | Storage Area | Path |
| --- | --- | --- |
| Long-term data for routine access | User Home | /home/$USER |
| Short-term project data for fast, batch-job access that is not shared | User Scratch | /lustre/or-hydra/cades-birthright/$USER |
| Short-term project data for fast, batch-job access that’s shared with other project members | Project Share | /lustre/or-hydra/cades-birthright/proj-shared/$USER |
| Short-term project data for fast, batch-job access that is shared globally | World Share | /lustre/or-hydra/cades-birthright/world-shared/$USER |
| Fast read/write access during a batch job | Local Scratch | $localscratch |
| Long term storage of data not currently in use \(Currently, only accessible using command adc\_xfer\) | User Temp | /data/adc/stratus/ |
| Placeholder | User Archive | HPSS \(if applicable\) |

USER HOME  
Home directories for each user are NFS-mounted on all CCLA Cluster systems and are intended to store long-term, frequently-accessed user data. User Home areas are not backed up. This file system does not generally provide the input/output \(I/O\) performance required by most compute jobs, and is not available to compute jobs on most systems. See the section [Data Retention, Purge, & Quota Summary](https://github.com/Doane-CCLA/docs/tree/6aa8e86be5b614a863272788de3d9c0182ee56c9/HPC/SHPC-5-data-transfer.md#Retention) for more details on applicable quotas, backups, purge, and retention timeframes.

USER SCRATCH  
Project members get an individual User Scratch directory; these reside in the high-capacity Lustre® file system on large, fast disk areas intended for global \(parallel\) access to temporary/scratch storage. Because of the scratch nature of the file system, it is not backed up and files are automatically purged on a regular basis. Files should not be retained in this file system for long, but rather should be migrated to HPSS Archive space as soon as the files are not actively being used. If a file system associated with your User Scratch directory is nearing capacity, the CCLA Cluster Support may contact you to request that you reduce the size of your Member scratch directory. See the section [Data Retention, Purge, & Quota Summary](https://github.com/Doane-CCLA/docs/tree/6aa8e86be5b614a863272788de3d9c0182ee56c9/HPC/SHPC-5-data-transfer.md#Retention) for more details on applicable quotas, backups, purge, and retention timeframes.

PROJECT SHARE  
Individual Project Share directories reside in the high-capacity Lustre file system on large, fast disk areas intended for global \(parallel\) access to temporary/scratch storage. Because of the scratch nature of the file system, it is not backed up. If a file system associated with Project Share storage is nearing capacity, the CCLA Cluster Support may contact the PI of the project to request that he or she reduce the size of the Project scratch directory. See the section [Data Retention, Purge, & Quota Summary](https://github.com/Doane-CCLA/docs/tree/6aa8e86be5b614a863272788de3d9c0182ee56c9/HPC/SHPC-5-data-transfer.md#Retention) for more details on applicable quotas, backups, purge, and retention timeframes.

WORLD SHARE  
Each project has a World Share directory that resides in the high-capacity Lustre file system on large, fast disk areas intended for global \(parallel\) access to temporary/scratch storage. Because of the scratch nature of the file system, it is not backed up. If a file system associated with World Share storage is nearing capacity, the CCLA Cluster may contact the PI of the project to request that he or she reduce the size of the World Work directory. See the section [Data Retention, Purge, & Quota Summary](https://github.com/Doane-CCLA/docs/tree/6aa8e86be5b614a863272788de3d9c0182ee56c9/HPC/SHPC-5-data-transfer.md#Retention) for more details on applicable quotas, backups, purge, and retention timeframes.

LOCAL SCRATCH STORAGE  
A fast solid state disk \(SSD\) area intended for parallel access to temporary storage in the form of scratch directories. This area is local to the computational node. This directory is, for example, intended to hold temporary and intermediate output generated by a user’s job. This is a run time only file system which is created at the start of a batch job and is purged at the end of the job. Files should not be retained in this file system and should be migrated to Lustre scratch or archival storage before finishing the job.

Path for local scratch storage is available during job runtime via environment variable `$localscratch`. Variable `$localscratch` typically has the form `/localscratch/tmp.$USER.$PBS_JOBID.or-condo-pbs01` and is specific to the user and to the scheduled job.

PROJECT STORAGE \(WARP\)  
A NFS area intended for temporary data storage for moving data off the Lustre file system. This area is local to the computational node. This directory is, for example, intended to hold temporary and intermediate output generated by a user’s job. This is a run time only file system which is created at the start of a batch job and is purged at the end of the job. Files should not be retained in this file system and should be migrated to Lustre scratch or archival storage before finishing the job.
